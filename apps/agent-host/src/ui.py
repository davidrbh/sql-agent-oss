import sys
import os
import chainlit as cl
from langchain_core.messages import HumanMessage

# --- MCP Imports ---
from mcp import ClientSession
from mcp.client.sse import sse_client
from infra.mcp.loader import get_agent_tools

# --- CONFIGURACI√ìN DE PATH ---
# Aseguramos que el sistema pueda encontrar el paquete 'src'
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(current_dir, 'src'))

# Importamos el cerebro del agente
from sql_agent.graph import build_graph

# URL interna de Docker
SIDECAR_URL = os.getenv("SIDECAR_URL", "http://mcp-mysql:3000")

# --- EVENTOS DE CHAINLIT ---

@cl.on_chat_start
async def on_chat_start():
    """
    Se ejecuta cuando un nuevo usuario inicia una sesi√≥n.
    Aqu√≠ inicializamos la conexi√≥n MCP, cargamos herramientas y construimos el grafo.
    """
    
    # 1. Feedback inicial
    msg = cl.Message(content="üîå Conectando con el Sidecar MySQL (MCP Protocol)...")
    await msg.send()

    try:
        # 2. Inicializar Conexi√≥n MCP Persistente
        # NOTA: Chainlit no tiene un "lifespan" global f√°cil para conexiones persistentes en modo async puro.
        # Estrategia: Abrimos el contexto y lo mantenemos vivo durante la sesi√≥n.
        # Usamos sse_client directamente sin 'async with' bloqueante, manejando el enter/exit manual
        # o manteniendo la referencia.
        
        # Monkey patch para mantener la session viva:
        # Realmente sse_client devuelve un context manager.
        # Vamos a usar aiohttp o httpx streams manualmente si es necesario, 
        # pero mcp.client.sse.sse_client es un helper.
        
        # TRUCO: Definimos una task que mantiene la conexi√≥n viva o usamos un wrapper.
        # Para simplificar en Chainlit, vamos a asumir conexi√≥n por request O
        # Mejor: Abrir la conexi√≥n y guardarla en user_session.
        
        # Pero `sse_client` es un AsyncContextManager.
        sse_ctx = sse_client(url=f"{SIDECAR_URL}/sse")
        streams = await sse_ctx.__aenter__() # Entramos manualmente
        
        cl.user_session.set("sse_ctx", sse_ctx) # Guardamos para cerrar luego
        
        client = ClientSession(streams[0], streams[1])
        await client.__aenter__() # <--- IMPORTANTE: Inicia el loop de lectura de mensajes
        await client.initialize()
        
        cl.user_session.set("mcp_client", client) # Guardamos cliente
        
        msg.content = "‚úÖ Conexi√≥n MCP Establecida. Cargando herramientas..."
        await msg.update()

        # 3. Cargar Herramientas
        tools = await get_agent_tools(client)
        
        tool_names = [t.name for t in tools]
        msg.content = f"üîß Herramientas cargadas: {tool_names}. Construyendo Cerebro..."
        await msg.update()

        # 4. Construir Grafo
        graph = build_graph(tools)
        cl.user_session.set("graph", graph)
        cl.user_session.set("history", [])

        # 5. Bienvenida Final
        msg.content = """üëã **¬°Hola! Soy SQL Agent v2.1**
        
Estoy conectado a tu entorno h√≠brido (Base de Datos + APIs).
Puedo ayudarte a:
* üìä Consultar datos hist√≥ricos SQL.
* üîå Verificar estados en tiempo real v√≠a API.
* üîÑ Corregir mis propios errores si algo falla.

_¬øQu√© necesitas saber hoy?_"""
        await msg.update()

    except Exception as e:
        msg.content = f"‚ùå **Error Fatal:** No se pudo conectar al Sidecar.\n\nError: {e}"
        await msg.update()

@cl.on_chat_end
async def on_chat_end():
    """Limpieza de recursos al cerrar la pesta√±a"""
    # 1. Cerrar Cliente MCP
    client = cl.user_session.get("mcp_client")
    if client:
        try:
            await client.__aexit__(None, None, None)
        except Exception as e:
            print(f"Error cerrando Cliente MCP: {e}")

    # 2. Cerrar Transporte SSE
    sse_ctx = cl.user_session.get("sse_ctx")
    if sse_ctx:
        print("üõë Cerrando conexi√≥n MCP...")
        try:
            await sse_ctx.__aexit__(None, None, None)
        except Exception as e:
            print(f"Error cerrando SSE: {e}")

@cl.on_message
async def on_message(message: cl.Message):
    """
    Manejador principal de mensajes.
    Recibe el input del usuario e invoca al agente.
    """
    # Recuperar estado
    graph = cl.user_session.get("graph")
    history = cl.user_session.get("history")
    
    # Placeholder de carga
    msg = cl.Message(content="")
    await msg.send()
    
    try:
        # A√±adir mensaje de usuario al historial local (LangGraph espera esto)
        history.append(HumanMessage(content=message.content))
        
        inputs = {
            "question": message.content,
            "messages": history
        }
        
        # Feedback visual
        msg.content = "üîÑ _Analizando intenci√≥n y ejecutando herramientas..._"
        await msg.update()
        
        # Ejecuci√≥n del Grafo (Async)
        config = {"recursion_limit": 50} # L√≠mite de seguridad
        result = await graph.ainvoke(inputs, config=config)
        
        # Actualizar historial con lo que devolvi√≥ el agente (incluye ToolMessages, AIMessages, etc)
        new_history = result["messages"]
        cl.user_session.set("history", new_history)
        
        # Extraer √∫ltima respuesta del asistente
        # LangGraph devuelve toda la lista, el √∫ltimo debe ser AIMessage
        final_response_content = new_history[-1].content
        
        # Enviar respuesta final
        msg.content = final_response_content
        await msg.update()
        
    except Exception as e:
        error_msg = f"‚ùå **Error Cr√≠tico:**\n\n```\n{str(e)}\n```"
        msg.content = error_msg
        await msg.update()
        print(f"Error en Chainlit handler: {e}")
