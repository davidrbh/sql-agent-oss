Generando radiograf√≠a de: /home/davidrbh/Documents/projects/sql-agent-oss

=== 1. ESTRUCTURA DEL PROYECTO (TREE) ===
sql-agent-oss/
    README.md
    .dockerignore
    .gitignore
    tsconfig.json
    pnpm-lock.yaml
    chainlit.md
    reporte_arquitectura.txt
    package.json
    .env
    pnpm-workspace.yaml
    .prettierrc
    debug_requests.py
    CHANGELOG.md
    .eslintrc.json
    CONTRIBUTING.md
    audit_project.py
    WARP.md
    .env.example
    turbo.json
    docker-compose.yml
    scripts/
        verify_mcp.py
        run_agent.py
        generate_dictionary.py
        validator.py
        list_models.py
    docs/
        05_whatsapp_integration.md
        06_mcp_migration_spec.md
        swagger.json
        04_optimization/
            modernization_roadmap.md
        01_architecture/
            project_boundaries.md
            tech_stack_decisions.md
            overview.md
        03_semantic_layer/
            semantic_spec.md
        02_setup_infra/
            infrastructure_spec.md
    data/
        dictionary.yaml
        chroma_db/
    services/
        mcp-mysql-sidecar/
            tsconfig.json
            .swcrc
            pnpm-lock.yaml
            package.json
            Dockerfile
            src/
                index.ts
    config/
        settings.yaml
        business_context.yaml
        prompts.yaml
    apps/
        agent-host/
            Dockerfile
            pyproject.toml
            src/
                ui.py
                main.py
                core/
                    utils/
                    llm/
                agent_core/
                    __init__.py
                    graph.py
                    core/
                        nodes.py
                        state.py
                    utils/
                        __init__.py
                        mcp_client.py
                        logger.py
                    llm/
                        __init__.py
                        factory.py
                    config/
                        __init__.py
                        loader.py
                    api/
                        __init__.py
                        loader.py
                infra/
                    __init__.py
                    mcp/
                        __init__.py
                        loader.py
                        manager.py
                features/
                    sql_analysis/
                        loader.py
                        config/
                        semantic/
                        tools/
                            api/
                channels/
                    __init__.py
                    whatsapp/
                        __init__.py
                        router.py
                old_sql_agent_trash/
                    core/
                api/
                    server.py
    deploy/
        docker/
    .files/
    .chainlit/
        config.toml
        translations/
            hi.json
            zh-TW.json
            mr.json
            el-GR.json
            ko.json
            fr-FR.json
            de-DE.json
            en-US.json
            zh-CN.json
            ta.json
            gu.json
            nl.json
            es.json
            ja.json
            bn.json
            te.json
            he-IL.json
            it.json
            ml.json
            kn.json

=== 2. CONTENIDO DE ARCHIVOS CR√çTICOS ===

--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/docker-compose.yml ---
services:
  # El Brazo (MySQL Sidecar)
  mcp-mysql:
    build:
      context: ./services/mcp-mysql-sidecar
    env_file:
      - .env
    environment:
      # Mapeo de variables del .env (DB_*) a las esperadas por el Sidecar (MYSQL_*)
      - MYSQL_HOST=${DB_HOST}
      - MYSQL_USER=${DB_USER}
      - MYSQL_PASSWORD=${DB_PASSWORD}
      - MYSQL_DATABASE=${DB_NAME}
      - MYSQL_PORT=3306
    ports:
      - "3000:3000"
    extra_hosts:
      - "host.docker.internal:host-gateway" # Para conectar a BD en localhost

  # El Cerebro (Agent Host)
  agent-host:
    build:
      context: ./apps/agent-host
    ports:
      - "8000:8000"
    # CAMBIO: Usamos uvicorn para correr server.py (Multicanal) en lugar de chainlit directo
    command: uvicorn src.api.server:app --host 0.0.0.0 --port 8000 --reload
    depends_on:
      - mcp-mysql
    env_file:
      - .env
    environment:
      - SIDECAR_URL=http://mcp-mysql:3000
    volumes:
      - ./apps/agent-host/src:/app/src # Hot reload logic support
      - ./config:/app/config
      - ./data:/app/data
      - ./docs:/app/docs # DOCUMENTACI√ìN (Swagger.json)

  # La Boca (WhatsApp HTTP API - WAHA)
  waha:
    image: devlikeapro/waha:latest
    ports:
      - "3001:3000" # Dashboard en puerto 3001
    env_file:
      - .env
    environment:
      # URL donde WAHA enviar√° los mensajes recibidos
      - WHATSAPP_WEBHOOK_URL=http://agent-host:8000/whatsapp/webhook
      # Eventos que queremos recibir
      - WHATSAPP_WEBHOOK_EVENTS=message
      # Puerto interno
      - PORT=3000
      # Seguridad (Mapeo desde .env)
      - WHATSAPP_API_KEY=${WAHA_API_KEY}
      - WHATSAPP_SWAGGER_USERNAME=${WHATSAPP_SWAGGER_USERNAME}
      - WHATSAPP_SWAGGER_PASSWORD=${WHATSAPP_SWAGGER_PASSWORD}
    volumes:
      - .waha_sessions:/app/sessions # Persistencia de sesi√≥n (QR)
    restart: on-failure


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/services/mcp-mysql-sidecar/src/index.ts ---
import "dotenv/config";

import cors from "@fastify/cors";
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { SSEServerTransport } from "@modelcontextprotocol/sdk/server/sse.js";
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} from "@modelcontextprotocol/sdk/types.js";
import Fastify, { FastifyReply, FastifyRequest } from "fastify";
import mysql from "mysql2/promise";
// import { z } from "zod";

const fastify = Fastify({
  logger: true,
});

// 1. Connection Pool (Outside handler to be persistent)
const pool = mysql.createPool({
  host: process.env.MYSQL_HOST,
  user: process.env.MYSQL_USER,
  password: process.env.MYSQL_PASSWORD,
  database: process.env.MYSQL_DATABASE,
  waitForConnections: true,
  connectionLimit: 10,
  queueLimit: 0,
});

const start = async () => {
  await fastify.register(cors, {
    origin: true, // Allow all origins for dev simplicity, tune for prod
  });

  // Bypass default JSON parsing so MCP SDK can consume the raw stream
  // "payload" here is the incoming stream
  fastify.addContentTypeParser("application/json", (req, payload, done) => {
    done(null, payload);
  });

  const server = new Server(
    {
      name: "mysql-sidecar",
      version: "1.0.0",
    },
    {
      capabilities: {
        tools: {},
      },
    },
  );

  // Define tools
  server.setRequestHandler(ListToolsRequestSchema, async () => {
    // Simulated async operation
    await Promise.resolve();
    return {
      tools: [
        {
          name: "query",
          description: "Execute a SQL query",
          inputSchema: {
            type: "object",
            properties: {
              sql: { type: "string" },
            },
            required: ["sql"],
          },
        },
      ],
    };
  });

  server.setRequestHandler(CallToolRequestSchema, async (request) => {
    if (request.params.name === "query") {
      // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
      const sql = Array.isArray(request.params.arguments?.sql)
        ? request.params.arguments?.sql[0]
        : request.params.arguments?.sql;

      if (typeof sql !== "string") {
        throw new TypeError("Invalid SQL argument");
      }

      try {
        // 2. REAL EXECUTION (Replaces Mock)
        const [rows] = await pool.execute(sql);

        return {
          content: [
            {
              type: "text",
              text: JSON.stringify(rows, null, 2), // Return real data as JSON
            },
          ],
        };
      } catch (error) {
        return {
          isError: true,
          content: [
            { type: "text", text: `MySQL Error: ${(error as Error).message}` },
          ],
        };
      }
    }
    throw new Error("Tool not found");
  });

  // Map of sessionId -> Transport
  const transports = new Map<string, SSEServerTransport>();

  fastify.get("/health", async () => {
    // Simulated async health check
    await Promise.resolve();
    return { status: "ok" };
  });

  fastify.get("/sse", async (req: FastifyRequest, reply: FastifyReply) => {
    // Delegate response handling to MCP SDK
    reply.hijack();

    const transport = new SSEServerTransport("/messages", reply.raw);

    const sessionId = transport.sessionId;
    transports.set(sessionId, transport);

    // We need to keep the connection open.
    await server.connect(transport);

    // Cleanup on close
    req.raw.on("close", () => {
      transports.delete(sessionId);
    });
  });

  fastify.post(
    "/messages",
    async (req: FastifyRequest, reply: FastifyReply) => {
      const sessionId = (req.query as { sessionId?: string }).sessionId;

      if (!sessionId || !transports.has(sessionId)) {
        reply.status(404).send({ error: "Session not found" });
        return;
      }

      const transport = transports.get(sessionId);
      if (transport) {
        // Delegate response handling to MCP SDK
        reply.hijack();

        // req.body is now the raw stream because of our custom parser
        // @ts-expect-error - req.body is raw stream
        await transport.handlePostMessage(req.body, reply.raw);
      }
    },
  );

  try {
    await fastify.listen({ port: 3000, host: "0.0.0.0" });
  } catch (error) {
    fastify.log.error(error);
    // eslint-disable-next-line unicorn/no-process-exit
    process.exit(1);
  }
};

void start();


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/config/business_context.yaml ---
version: "2.5"
project: "credivibes_ai_context"

meta:
  currency_format: "USD"
  time_zone: "America/Caracas"
  description: >
    Capa sem√°ntica MAESTRA para la plataforma BNPL Credivibes.

    *** REGLAS DE ORO GLOBALES (MUST READ) ***:

    1. PREFERENCIA POR COLUMNAS TOTALIZADORAS: Si existe 'balance' o 'total', √öSALA.
       NO calcules sumas manuales (SUM) sobre transacciones a menos que sea un reporte de desglose.
       Conf√≠a ciegamente en el dato almacenado en la tabla padre.

    2. MONEDA BASE (USD):
       - Todos los montos financieros (deuda, l√≠mites, precios) est√°n almacenados en USD.
       - Montos en VES solo existen en logs bancarios y pagos reportados ('amount_ves').
       - Conversi√≥n: siempre usa la tasa almacenada en el registro (amount / rate).

    3. JOINS H√çBRIDOS (UUID vs ID):
       - La regla general es JOIN por UUID (users.uuid = purchases.users_id).
       - EXCEPCIONES IMPORTANTES: 'credit_evaluations' usa ID num√©rico (users.id) y 'merchant_branches' usa ID num√©rico de merchant (merchant.id).
       - Verifica siempre la secci√≥n 'relationships' antes de generar SQL.

entities:
  # Actores
  - name: user
    type: primary
    primary_key: uuid
    synonyms:
      [
        "cliente",
        "comprador",
        "deudor",
        "solicitante",
        "usuario",
        "persona",
        "persona natural",
        "persona jur√≠dica",
      ]
  - name: merchant
    type: primary
    primary_key: uuid
    synonyms:
      [
        "comercio",
        "tienda",
        "aliado",
        "proveedor",
        "negocio",
        "empresa",
        "negocio",
      ]
  - name: merchant_branch
    type: primary
    primary_key: uuid
    synonyms: ["sucursal", "sede", "filial"]
  - name: merchant_user
    type: primary
    primary_key: uuid
    synonyms:
      [
        "vendedor",
        "cajero",
        "empleado",
        "funcionario",
        "personal",
        "trabajador",
      ]

  # Transacciones
  - name: purchase
    type: primary
    primary_key: uuid
    synonyms:
      [
        "cr√©dito",
        "orden",
        "financiamiento",
        "compra",
        "venta",
        "pago",
        "cobro",
        "factura",
        "factura de venta",
        "factura de cr√©dito",
      ]
  - name: purchase_intent
    type: primary
    primary_key: id
    synonyms: ["intento", "solicitud", "pre-aprobaci√≥n"]
  - name: purchase_payment
    type: primary
    primary_key: uuid
    synonyms: ["cuota", "letra", "installment", "pago", "cobro"]

  # Dinero & Auditor√≠a
  - name: verified_payment
    type: primary
    primary_key: uuid
    synonyms:
      [
        "pago verificado",
        "pago reportado",
        "auditor√≠a",
        "pago",
        "cobro",
        "factura",
        "factura de venta",
        "factura de cr√©dito",
      ]
  - name: bank_notification
    type: primary
    primary_key: id
    synonyms: ["log bancario", "notificaci√≥n de banco", "pago crudo", "webhook"]

models:
  # -----------------------------------------------------------------
  # MODULE: USERS & RISK
  # -----------------------------------------------------------------
  - name: users
    source: "bnplsite_credivibes.users"
    entities:
      - name: user
        type: primary
        col: uuid
    dimensions:
      - name: email
        type: string
        col: email
        pii: true
      - name: status
        type: categorical
        col: status
        try_cast_to: integer
        description: "1: Activo, 0: Inactivo"
        allowed_values: ["1", "0"]
      - name: created_at
        type: time
        col: created_at
    measures:
      - name: current_debt
        type: custom
        col: balance
        description: >
          Deuda total pendiente. FUENTE DE VERDAD.
          NOTA: Un valor positivo significa que el usuario DEBE dinero.
          NO intentar calcular esto sumando compras; usa siempre este valor.
      - name: credit_limit
        type: custom
        col: credit_limit

  - name: users_profile
    source: "bnplsite_credivibes.users_profile"
    entities:
      - name: user
        type: foreign
        col: users_id
    dimensions:
      - name: name
        type: string
        col: name
      - name: lastname
        type: string
        col: lastname
      - name: phone
        type: string
        col: phone
        pii: true
      - name: document
        type: string
        col: document
        pii: true

  - name: users_score
    source: "bnplsite_credivibes.users_score"
    entities:
      - name: user
        type: foreign
        col: users_id # Relaci√≥n por UUID
    dimensions:
      - name: score
        type: number
        col: score
        description: "Puntaje de cr√©dito interno (Score)."

  - name: credit_evaluations
    source: "bnplsite_credivibes.credit_evaluations"
    entities:
      - name: user
        type: foreign
        col: user_id # WARNING: Uses Numeric ID
    dimensions:
      - name: final_credit_limit
        type: number
        col: final_credit_limit
      - name: evaluation_result
        type: string
        col: evaluation_result
    measures:
      - name: limit_granted
        type: max
        col: final_credit_limit

  # -----------------------------------------------------------------
  # MODULE: MERCHANT
  # -----------------------------------------------------------------
  - name: merchant
    source: "bnplsite_credivibes.merchant"
    entities:
      - name: merchant
        type: primary
        col: uuid
    dimensions:
      - name: name
        type: string
        col: name
      - name: trade_name
        type: string
        col: trade_name
      - name: montoMinimo
        type: number
        col: montoMinimo
        description: "Monto m√≠nimo de venta para financiar."
      - name: porcentajesInicial
        type: string
        col: porcentajesInicial
        description: "JSON con % de inicial permitidos."
      - name: cuotasPermitidas
        type: string
        col: cuotasPermitidas
        description: "JSON con plazos permitidos."
    measures:
      - name: monthly_fee
        type: sum
        col: monthly_fee

  - name: merchant_branches
    source: "bnplsite_credivibes.merchant_branches"
    entities:
      - name: merchant_branch
        type: primary
        col: uuid
      - name: merchant
        type: foreign
        col: merchant_id # WARNING: Uses Numeric ID
    dimensions:
      - name: name
        type: string
        col: name
      - name: state
        type: string
        col: estado

  - name: merchant_users
    source: "bnplsite_credivibes.merchant_users"
    entities:
      - name: merchant_user
        type: primary
        col: uuid
      - name: merchant
        type: foreign
        col: merchant_id
    dimensions:
      - name: role
        type: categorical
        col: role
      - name: username
        type: string
        col: nickname

  - name: merchant_user_branches
    source: "bnplsite_credivibes.merchant_user_branches"
    entities:
      - name: merchant_user
        type: foreign
        col: merchant_user_id # ID num√©rico
      - name: merchant_branch
        type: foreign
        col: branch_id # ID num√©rico

  # -----------------------------------------------------------------
  # MODULE: PURCHASES (Action)
  # -----------------------------------------------------------------
  - name: purchases
    source: "bnplsite_credivibes.purchase"
    entities:
      - name: purchase
        type: primary
        col: uuid
      - name: user
        type: foreign
        col: users_id
      - name: merchant
        type: foreign
        col: merchant_id
      - name: merchant_branch
        type: foreign
        col: merchant_branches_id
    dimensions:
      - name: status
        type: categorical
        col: status
        try_cast_to: integer
        description: "0: Progreso, 1: Completado, 2: Anulado"
        allowed_values: ["0", "1", "2"]
      - name: transaction_id
        type: string
        col: transaction_id
      - name: created_at
        type: time
        col: created_at
      - name: is_overdue
        type: boolean
        sql: "EXISTS (SELECT 1 FROM purchase_payment pp WHERE pp.purchase_id = purchase.uuid AND pp.type = 'quote' AND pp.status != 1 AND pp.valid_until_time < UNIX_TIMESTAMP(NOW()))"
    measures:
      - name: total_billed
        type: sum
        col: total
        description: "Monto Venta Total (Principal + Intereses + Inicial)."
      - name: financed_amount
        type: sum
        sql: "purchase.total - purchase.initial_fee"
        description: "Monto Financiado (Deuda neta inicial)."

  - name: purchase_intents
    source: "bnplsite_credivibes.purchase_intent"
    entities:
      - name: purchase_intent
        type: primary
        col: id
        col_uuid: uuid
    dimensions:
      - name: status
        type: categorical
        col: status
        try_cast_to: integer
        description: "0: Pendiente, 1: Aprobado, 2: Rechazado"
        allowed_values: ["0", "1", "2"]
      - name: created_at
        type: time
        col: created_at
    measures:
      - name: amount_requested
        type: sum
        col: total

  - name: purchase_payments
    source: "bnplsite_credivibes.purchase_payment"
    entities:
      - name: purchase_payment
        type: primary
        col: uuid
      - name: purchase
        type: foreign
        col: purchase_id
    dimensions:
      - name: type
        type: categorical
        col: type
        allowed_values: ["quote", "initial_fee"]
      - name: status
        type: categorical
        col: status
        try_cast_to: integer
        description: "0: Pendiente, 1: Pagado, 2: Anulado, 5: Parcial"
        allowed_values: ["0", "1", "2", "5"]
      - name: due_date
        type: time
        sql: "FROM_UNIXTIME(valid_until_time)"
    measures:
      - name: amount_due
        type: sum
        col: amount
      - name: amount_paid
        type: sum
        col: amount_payed

  # -----------------------------------------------------------------
  # MODULE: PAYMENTS & BANKING
  # -----------------------------------------------------------------
  - name: verified_payments
    source: "bnplsite_credivibes.payment_checked"
    entities:
      - name: verified_payment
        type: primary
        col: uuid
      - name: purchase
        type: foreign
        col: purchase_id
      - name: user
        type: foreign
        col: users_id
    dimensions:
      - name: method
        type: categorical
        col: type
        allowed_values: ["mobile", "transfer", "c2p", "cash"]
      - name: reference
        type: string
        col: reference
      - name: bank_code
        type: string
        col: bank_code
      - name: created_at
        type: time
        col: created_at
    measures:
      - name: amount_ves
        type: sum
        col: amount
        description: "Monto en Moneda Local (VES)."
      - name: exchange_rate
        type: avg
        col: convertion_rate
      - name: amount_usd
        type: sum
        sql: "payment_checked.amount / payment_checked.convertion_rate"
        description: "Monto calculado en USD."

  - name: bank_notifications
    source: "bnplsite_credivibes.bank_payment_notifications"
    entities:
      - name: bank_notification
        type: primary
        col: id
    dimensions:
      - name: bank_ref
        type: string
        col: originating_bank_reference
        description: "Referencia bancaria (CRUDA)."
      - name: sender_phone
        type: string
        col: payer_phone
      - name: status
        type: string
        col: status
        allowed_values: ["received", "processed"]
      - name: created_at
        type: time
        col: created_at
    measures:
      - name: amount_ves
        type: sum
        col: amount_ves
        description: "Monto reportado por el banco (Siempre VES)."

relationships:
  # Users Relationships
  - from_model: users_profile
    to_model: users
    join_type: one_to_one
    on: "users_profile.users_id = users.uuid"
  - from_model: users_score
    to_model: users
    join_type: one_to_one
    on: "users_score.users_id = users.uuid"
  - from_model: credit_evaluations
    to_model: users
    join_type: many_to_one
    on: "credit_evaluations.user_id = users.id" # Numeric JOIN

  # Purchase Core
  - from_model: purchases
    to_model: users
    join_type: many_to_one
    on: "purchases.users_id = users.uuid"
  - from_model: purchases
    to_model: merchant
    join_type: many_to_one
    on: "purchases.merchant_id = merchant.uuid"
  - from_model: purchases
    to_model: merchant_branches
    join_type: many_to_one
    on: "purchases.merchant_branches_id = merchant_branches.uuid"

  # Purchase Details
  - from_model: purchase_payments
    to_model: purchases
    join_type: many_to_one
    on: "purchase_payments.purchase_id = purchases.uuid"

  # Payments Audit
  - from_model: verified_payments
    to_model: purchases
    join_type: many_to_one
    on: "verified_payments.purchase_id = purchases.uuid"
  - from_model: verified_payments
    to_model: users
    join_type: many_to_one
    on: "verified_payments.users_id = users.uuid"

  # Merchant Internal
  - from_model: merchant_branches
    to_model: merchant
    join_type: many_to_one
    on: "merchant_branches.merchant_id = merchant.id" # Numeric JOIN

metrics:
  - name: average_order_value
    type: ratio
    numerator: purchases.total_billed
    denominator: purchases.count

  - name: delinquency_rate
    description: "Tasa de Morosidad (Pagos vencidos vs Total)."
    type: ratio
    numerator:
      type: count
      model: purchase_payments
      filter: "type = 'quote' AND status != 1 AND valid_until_time < UNIX_TIMESTAMP(NOW())"
    denominator:
      type: count
      model: purchase_payments
      filter: "type = 'quote' AND status != 1"

  - name: intent_approval_rate
    description: "Tasa de Aprobaci√≥n: % de intentos de compra que resultan exitosos."
    type: ratio
    numerator:
      type: count
      model: purchase_intents
      filter: "status = 1"
    denominator:
      type: count
      model: purchase_intents

  - name: average_financed_amount
    description: "Ticket Promedio Financiado: Promedio de deuda real originada (Excluye inicial)."
    type: ratio
    numerator:
      type: sum
      sql: "total - initial_fee" # Explicit SQL to avoid dependency resolution issues
    denominator: purchases.count

  - name: active_debtors_ratio
    description: "% de Usuarios con Deuda Activa vs Total Usuarios."
    type: ratio
    numerator:
      type: count
      model: users
      filter: "balance > 0"
    denominator:
      type: count
      model: users
      filter: "status = '1'"

  - name: loan_completion_rate
    description: "Tasa de Finalizaci√≥n: % de cr√©ditos pagados totalmente."
    type: ratio
    numerator:
      type: count
      model: purchases
      filter: "status = 1"
    denominator:
      type: count
      model: purchases

business_rules:
  - name: "Regla de Fechas Quincenales"
    description: "Vencimientos: Compras d√≠as 1-11 -> Vence 15; 12-26 -> Vence FinMes; 27-31 -> Vence 15 Pr√≥ximo."

  - name: "Conversi√≥n de Moneda"
    description: "Para verificar montos en USD de pagos reportados: verified_payments.amount (VES) / verified_payments.convertion_rate."

  - name: "Conciliaci√≥n Bancaria"
    description: "bank_notifications es el LOG crudo. verified_payments es el pago PROCESADO. Un join entre ellos es posible via referencia, pero no siempre es 1:1."

  - name: "Anulaci√≥n"
    description: "Compras con status=2 (Anulado) deben ser excluidas de reportes de venta y deuda real."

  - name: "Pol√≠tica de Riesgo Cero (Bloqueo por Mora)"
    description: "Un usuario NO puede solicitar nuevos cr√©ditos si tiene CUALQUIER cuota vencida (is_overdue = TRUE) en cr√©ditos anteriores. El sistema bloquea autom√°ticamente nuevos intentos."

  - name: "Pagos en Cascada (Waterfall)"
    description: "Distribuci√≥n autom√°tica de dinero: Los pagos cubren primero la deuda m√°s antigua. Si un pago excede el monto de la cuota actual, el excedente ('surplus') se aplica inmediatamente a la siguiente cuota, generando pagos parciales si es necesario."

  - name: "Configuraci√≥n Financiera por Comercio"
    description: "Las condiciones de cr√©dito (Recargo, % Inicial, Plazos) NO son universales. Cada 'merchant' define sus reglas en 'cuotasPermitidas' y 'porcentajesInicial'. No asumir condiciones est√°ndar para todos."

usage_examples:
  - question: "¬øQu√© pagos m√≥viles llegaron hoy?"
    sql: "SELECT reference, amount / convertion_rate as amount_usd FROM payment_checked WHERE type = 'mobile' AND created_at >= CURDATE()"

  - question: "¬øCu√°ntos usuarios tengo con Score > 500?"
    sql: "SELECT COUNT(*) FROM users_score WHERE score > 500"

  - question: "¬øCu√°les son las cuotas que vencen en los pr√≥ximos 7 d√≠as? (Cobranza)"
    sql: "SELECT u.email, pp.amount, FROM_UNIXTIME(pp.valid_until_time) as due_date FROM purchase_payment pp JOIN purchases p ON pp.purchase_id = p.uuid JOIN users u ON p.users_id = u.uuid WHERE pp.status = 0 AND pp.type = 'quote' AND pp.valid_until_time BETWEEN UNIX_TIMESTAMP(NOW()) AND UNIX_TIMESTAMP(DATE_ADD(NOW(), INTERVAL 7 DAY))"

  - question: "¬øQu√© comercios tienen m√°s ventas (en USD) este mes?"
    sql: "SELECT m.trade_name, SUM(p.total) as sales FROM purchase p JOIN merchant m ON p.merchant_id = m.uuid WHERE p.status = 1 AND p.created_at >= DATE_FORMAT(NOW(), '%Y-%m-01') GROUP BY m.trade_name ORDER BY sales DESC LIMIT 5"

  - question: "¬øExisten pagos en el banco que no hemos registrado en el sistema? (Hu√©rfanos)"
    sql: "SELECT b.originating_bank_reference, b.amount_ves, b.payer_phone FROM bank_payment_notifications b LEFT JOIN payment_checked v ON b.originating_bank_reference = v.reference WHERE v.uuid IS NULL AND b.created_at >= CURDATE()"

  - question: "Calcular la tasa de aprobaci√≥n de solicitudes de cr√©dito de la √∫ltima semana."
    sql: "SELECT COUNT(CASE WHEN status = 1 THEN 1 END) * 100.0 / COUNT(*) as approval_rate FROM purchase_intent WHERE created_at >= DATE_SUB(NOW(), INTERVAL 1 WEEK)"


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/ui.py ---
import sys
import os
import chainlit as cl
from langchain_core.messages import HumanMessage

# --- MCP Imports ---
from mcp import ClientSession
from mcp.client.sse import sse_client
from infra.mcp.loader import get_agent_tools

# --- CONFIGURACI√ìN DE PATH ---
# Aseguramos que el sistema pueda encontrar el paquete 'src'
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(current_dir, 'src'))

# Importamos el cerebro del agente
from agent_core.graph import build_graph

# URL interna de Docker
SIDECAR_URL = os.getenv("SIDECAR_URL", "http://mcp-mysql:3000")

# --- EVENTOS DE CHAINLIT ---

@cl.on_chat_start
async def on_chat_start():
    """
    Se ejecuta cuando un nuevo usuario inicia una sesi√≥n.
    Aqu√≠ inicializamos la conexi√≥n MCP, cargamos herramientas y construimos el grafo.
    """
    
    # 1. Feedback inicial
    msg = cl.Message(content="üîå Conectando con el Sidecar MySQL (MCP Protocol)...")
    await msg.send()

    try:
        # 2. Inicializar Conexi√≥n MCP Persistente
        # NOTA: Chainlit no tiene un "lifespan" global f√°cil para conexiones persistentes en modo async puro.
        # Estrategia: Abrimos el contexto y lo mantenemos vivo durante la sesi√≥n.
        # Usamos sse_client directamente sin 'async with' bloqueante, manejando el enter/exit manual
        # o manteniendo la referencia.
        
        # Monkey patch para mantener la session viva:
        # Realmente sse_client devuelve un context manager.
        # Vamos a usar aiohttp o httpx streams manualmente si es necesario, 
        # pero mcp.client.sse.sse_client es un helper.
        
        # TRUCO: Definimos una task que mantiene la conexi√≥n viva o usamos un wrapper.
        # Para simplificar en Chainlit, vamos a asumir conexi√≥n por request O
        # Mejor: Abrir la conexi√≥n y guardarla en user_session.
        
        # Pero `sse_client` es un AsyncContextManager.
        sse_ctx = sse_client(url=f"{SIDECAR_URL}/sse")
        streams = await sse_ctx.__aenter__() # Entramos manualmente
        
        cl.user_session.set("sse_ctx", sse_ctx) # Guardamos para cerrar luego
        
        client = ClientSession(streams[0], streams[1])
        await client.__aenter__() # <--- IMPORTANTE: Inicia el loop de lectura de mensajes
        await client.initialize()
        
        cl.user_session.set("mcp_client", client) # Guardamos cliente
        
        msg.content = "‚úÖ Conexi√≥n MCP Establecida. Cargando herramientas..."
        await msg.update()

        # 3. Cargar Herramientas
        tools = await get_agent_tools(client)
        
        tool_names = [t.name for t in tools]
        msg.content = f"üîß Herramientas cargadas: {tool_names}. Construyendo Cerebro..."
        await msg.update()

        # 4. Construir Grafo
        graph = build_graph(tools)
        cl.user_session.set("graph", graph)
        cl.user_session.set("history", [])

        # 5. Bienvenida Final
        msg.content = """üëã **¬°Hola! Soy SQL Agent v2.1**
        
Estoy conectado a tu entorno h√≠brido (Base de Datos + APIs).
Puedo ayudarte a:
* üìä Consultar datos hist√≥ricos SQL.
* üîå Verificar estados en tiempo real v√≠a API.
* üîÑ Corregir mis propios errores si algo falla.

_¬øQu√© necesitas saber hoy?_"""
        await msg.update()

    except Exception as e:
        msg.content = f"‚ùå **Error Fatal:** No se pudo conectar al Sidecar.\n\nError: {e}"
        await msg.update()

@cl.on_chat_end
async def on_chat_end():
    """Limpieza de recursos al cerrar la pesta√±a"""
    # 1. Cerrar Cliente MCP
    client = cl.user_session.get("mcp_client")
    if client:
        try:
            await client.__aexit__(None, None, None)
        except Exception as e:
            print(f"Error cerrando Cliente MCP: {e}")

    # 2. Cerrar Transporte SSE
    sse_ctx = cl.user_session.get("sse_ctx")
    if sse_ctx:
        print("üõë Cerrando conexi√≥n MCP...")
        try:
            await sse_ctx.__aexit__(None, None, None)
        except Exception as e:
            print(f"Error cerrando SSE: {e}")

@cl.on_message
async def on_message(message: cl.Message):
    """
    Manejador principal de mensajes.
    Recibe el input del usuario e invoca al agente.
    """
    # Recuperar estado
    graph = cl.user_session.get("graph")
    history = cl.user_session.get("history")
    
    # Placeholder de carga
    msg = cl.Message(content="")
    await msg.send()
    
    try:
        # A√±adir mensaje de usuario al historial local (LangGraph espera esto)
        history.append(HumanMessage(content=message.content))
        
        inputs = {
            "question": message.content,
            "messages": history
        }
        
        # Feedback visual
        msg.content = "üîÑ _Analizando intenci√≥n y ejecutando herramientas..._"
        await msg.update()
        
        # Ejecuci√≥n del Grafo (Async)
        config = {"recursion_limit": 50} # L√≠mite de seguridad
        result = await graph.ainvoke(inputs, config=config)
        
        # Actualizar historial con lo que devolvi√≥ el agente (incluye ToolMessages, AIMessages, etc)
        new_history = result["messages"]
        cl.user_session.set("history", new_history)
        
        # Extraer √∫ltima respuesta del asistente
        # LangGraph devuelve toda la lista, el √∫ltimo debe ser AIMessage
        final_response_content = new_history[-1].content
        
        # Enviar respuesta final
        msg.content = final_response_content
        await msg.update()
        
    except Exception as e:
        error_msg = f"‚ùå **Error Cr√≠tico:**\n\n```\n{str(e)}\n```"
        msg.content = error_msg
        await msg.update()
        print(f"Error en Chainlit handler: {e}")


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/main.py ---
import sys
import os
import chainlit as cl
from langchain_core.messages import HumanMessage

# --- MCP Imports ---
from mcp import ClientSession
from mcp.client.sse import sse_client
from infra.mcp.manager import MCPSessionManager

# --- FEATURE Imports (Arquitectura H√≠brida) ---
# Cargamos la "feature" de An√°lisis SQL espec√≠ficamente.
from features.sql_analysis.loader import get_sql_tools, get_sql_system_prompt

# --- CONFIGURACI√ìN DE PATH ---
# Aseguramos que el sistema pueda encontrar el paquete 'src'
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(current_dir, 'src'))

# Importamos el cerebro del agente
from agent_core.graph import build_graph

# URL interna de Docker
SIDECAR_URL = os.getenv("SIDECAR_URL", "http://mcp-mysql:3000")

# --- EVENTOS DE CHAINLIT ---

@cl.on_chat_start
async def on_chat_start():
    """
    Se ejecuta cuando un nuevo usuario inicia una sesi√≥n.
    Aqu√≠ inicializamos la conexi√≥n MCP, cargamos herramientas y construimos el grafo.
    """
    
    # 1. Feedback inicial
    msg = cl.Message(content="üîå Conectando con el Sidecar MySQL (MCP Protocol)...")
    await msg.send()

    try:
        # 2. Inicializar Conexi√≥n MCP Persistente (Auto-Reconnect)
        # Usamos MCPSessionManager para manejar reconexiones autom√°ticas si el socket se cierra.
        mcp_manager = MCPSessionManager(SIDECAR_URL)
        await mcp_manager.connect()
        
        cl.user_session.set("mcp_manager", mcp_manager)
        
        msg.content = "‚úÖ Conexi√≥n MCP Establecida. Cargando herramientas..."
        await msg.update()

        # 3. Cargar Herramientas y Contexto (Feature SQL)
        # Usamos el loader espec√≠fico de la feature SQL
        tools = await get_sql_tools(mcp_manager)
        system_prompt = get_sql_system_prompt()
        
        tool_names = [t.name for t in tools]
        msg.content = f"üîß Herramientas cargadas: {tool_names}. Construyendo Cerebro..."
        await msg.update()

        # 4. Construir Grafo
        # Ahora inyectamos expl√≠citamente el prompt y las herramientas
        graph = build_graph(tools, system_prompt)
        cl.user_session.set("graph", graph)
        cl.user_session.set("history", [])

        # 5. Bienvenida Final
        msg.content = """üëã **¬°Hola! Soy SQL Agent v2.1**
        
Estoy conectado a tu entorno h√≠brido (Base de Datos + APIs).
Puedo ayudarte a:
* üìä Consultar datos hist√≥ricos SQL.
* üîå Verificar estados en tiempo real v√≠a API.
* üîÑ Corregir mis propios errores si algo falla.

_¬øQu√© necesitas saber hoy?_"""
        await msg.update()

    except Exception as e:
        msg.content = f"‚ùå **Error Fatal:** No se pudo conectar al Sidecar.\n\nError: {e}"
        await msg.update()

@cl.on_chat_end
async def on_chat_end():
    """Limpieza de recursos al cerrar la pesta√±a"""
    # 1. Cerrar Cliente MCP
    manager = cl.user_session.get("mcp_manager")
    if manager:
        await manager.close()
        try:
            await client.__aexit__(None, None, None)
        except Exception as e:
            print(f"Error cerrando Cliente MCP: {e}")

    # 2. Cerrar Transporte SSE
    sse_ctx = cl.user_session.get("sse_ctx")
    if sse_ctx:
        print("üõë Cerrando conexi√≥n MCP...")
        try:
            await sse_ctx.__aexit__(None, None, None)
        except Exception as e:
            print(f"Error cerrando SSE: {e}")

@cl.on_message
async def on_message(message: cl.Message):
    """
    Manejador principal de mensajes.
    Recibe el input del usuario e invoca al agente.
    """
    # Recuperar estado
    graph = cl.user_session.get("graph")
    history = cl.user_session.get("history")
    
    # Placeholder de carga
    msg = cl.Message(content="")
    await msg.send()
    
    try:
        # A√±adir mensaje de usuario al historial local (LangGraph espera esto)
        history.append(HumanMessage(content=message.content))
        
        inputs = {
            "question": message.content,
            "messages": history
        }
        
        # Feedback visual
        msg.content = "üîÑ _Analizando intenci√≥n y ejecutando herramientas..._"
        await msg.update()
        
        # Ejecuci√≥n del Grafo (Async)
        config = {"recursion_limit": 150} # L√≠mite de seguridad aumentado
        result = await graph.ainvoke(inputs, config=config)
        
        # Actualizar historial con lo que devolvi√≥ el agente (incluye ToolMessages, AIMessages, etc)
        new_history = result["messages"]
        cl.user_session.set("history", new_history)
        
        # Extraer √∫ltima respuesta del asistente
        # LangGraph devuelve toda la lista, el √∫ltimo debe ser AIMessage
        final_response_content = new_history[-1].content
        
        # Enviar respuesta final
        msg.content = final_response_content
        await msg.update()
        
    except Exception as e:
        error_msg = f"‚ùå **Error Cr√≠tico:**\n\n```\n{str(e)}\n```"
        msg.content = error_msg
        await msg.update()
        print(f"Error en Chainlit handler: {e}")


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/graph.py ---
import os
from typing import List
from langchain_openai import ChatOpenAI
from langchain_core.tools import BaseTool
from langchain_core.messages import ToolMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode

# Importa tu estado (aseg√∫rate de que coincida con tu archivo actual)
from agent_core.core.state import AgentState 

# --- La l√≥gica del core es GEN√âRICA ---
# No sabe nada de SQL, ni de negocio.
# Solo recibe herramientas y prompts.

def build_graph(tools: List[BaseTool], system_prompt: str):
    """
    Construye el Grafo del Agente inyectando las herramientas din√°micas y el prompt.
    """
    # Configurar el LLM con las herramientas reales
    # Habilitar manejo de errores para que el Agente pueda recuperarse de fallos SQL
    for tool in tools:
        tool.handle_tool_error = True

    # Usamos DeepSeek como LLM principal
    llm = ChatOpenAI(
        model="deepseek-chat",
        temperature=0,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com"
    )
    llm_with_tools = llm.bind_tools(tools)

    # 2. Nodo del Agente (El Cerebro)
    def agent_node(state: AgentState):
        messages = state["messages"]
        
        # Inyectar System Prompt si no existe
        if not isinstance(messages[0], SystemMessage):
            # Usamos el prompt pasado por argumento
            messages = [SystemMessage(content=system_prompt)] + messages
            
        print(f"DEBUG MESSAGES: {messages}") 

        # --- SANITIZATION FOR DEEPSEEK ---
        # DeepSeek API (OpenAI compat) falla si el contenido de ToolMessage es una lista de dicts.
        # LangChain ToolNode a veces devuelve bloques de contenido multimodal. Lo aplanamos a texto.
        sanitized_messages = []
        for m in messages:
            if isinstance(m, ToolMessage) and isinstance(m.content, list):
                # Unir todos los bloques de texto
                text_content = "".join([
                    block.get("text", "") for block in m.content 
                    if isinstance(block, dict) and block.get("type") == "text"
                ])
                # Crear nueva copia con contenido string
                new_m = ToolMessage(
                    content=text_content, 
                    tool_call_id=m.tool_call_id, 
                    name=m.name,
                    artifact=m.artifact
                )
                sanitized_messages.append(new_m)
            else:
                sanitized_messages.append(m)

        response = llm_with_tools.invoke(sanitized_messages)
        return {"messages": [response]}

    # 3. Nodo de Herramientas (El Brazo)
    # ToolNode de LangGraph ejecuta autom√°ticamente la herramienta que el LLM pida
    # handle_tool_errors=True permite que el nodo capture excepciones y devuelva un mensaje de error al LLM
    tool_node = ToolNode(tools, handle_tool_errors=True)

    # 4. Definici√≥n del Flujo (Workflow)
    workflow = StateGraph(AgentState)

    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)

    workflow.set_entry_point("agent")

    # L√≥gica condicional: ¬øEl LLM quiere usar una herramienta o responder al usuario?
    def should_continue(state):
        last_message = state["messages"][-1]
        if last_message.tool_calls:
            return "tools"
        return END

    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            END: END
        }
    )

    # El agente vuelve a pensar despu√©s de usar una herramienta
    workflow.add_edge("tools", "agent")

    return workflow.compile()


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/core/nodes.py ---
import os
import ast
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from sqlalchemy import text
from langgraph.prebuilt import create_react_agent  # MOVED TO TOP-LEVEL

# Importaciones de Arquitectura
from agent_core.llm.factory import LLMFactory
from agent_core.core.state import AgentState
from agent_core.config.loader import ConfigLoader
# from agent_core.database.connection import DatabaseManager # Legacy
from agent_core.utils.mcp_client import mcp_manager

# --- IMPORTACI√ìN DE LA API (NUEVA UBICACI√ìN) ---
try:
    from agent_core.api.loader import load_api_tools, load_swagger_summary
    API_AVAILABLE = True
except ImportError as e:
    API_AVAILABLE = False
    print(f"‚ö†Ô∏è [Warning] No se pudo cargar el m√≥dulo API: {e}")

# Rutas
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
DICTIONARY_PATH = os.path.join(BASE_DIR, 'data', 'dictionary.yaml')

class AgentNodes:
    
    def __init__(self):
        self.settings = ConfigLoader.load_settings()
        self.llm = LLMFactory.create(temperature=0)
        
        # Carga Diccionario SQL
        try:
            with open(DICTIONARY_PATH, 'r', encoding='utf-8') as f:
                self.data_dictionary = f.read()
        except FileNotFoundError:
            self.data_dictionary = "No data dictionary found."

        # Carga Herramientas API
        self.api_tools = load_api_tools() if API_AVAILABLE else []

        # --- OPTIMIZACI√ìN SINGLETON (Fase 1) ---
        # Inicializamos el Agente API una sola vez al arranque para evitar overhead
        if self.api_tools:
            print("üöÄ [Init] Compilando Agente API (Singleton)...")
            api_instructions = """
            Eres un operador de APIs preciso.
            REGLAS:
            1. Usa las herramientas para obtener datos REALES.
            2. Si falla, reporta el error exacto.
            3. NO inventes datos.
            4. USA EL CONTEXTO: Si el usuario dice "ese endpoint", refi√©rete al √∫ltimo mencionado en la charla.
            """
            # Pre-construimos el agente. Al usar state_modifier, inyectamos las instrucciones sistema
            # [FIX] state_modifier no disponible en esta versi√≥n, inyectamos SystemMessage manualmente en runtime
            self.api_agent_executor = create_react_agent(self.llm, self.api_tools)
        else:
            self.api_agent_executor = None

    # Guardamos las instrucciones como miembro de clase para usar luego
    API_INSTRUCTIONS = """
            Eres un operador de APIs preciso.
            
            REGLAS OPERATIVAS:
            1. CONSULTAS DE META-DATA (¬øQu√© endpoints hay? ¬øCu√°l uso?): 
               - RESPONDE usando SOLO la 'Documentaci√≥n Din√°mica' abajo. 
               - NO uses herramientas (requests_get) para esto.
               
            2. CONSULTAS DE DATOS REALES (Trae usuarios, busca el ID 5):
               - USA la herramienta 'requests_get' para obtener la respuesta de la API.
               - Si falla la conexi√≥n, reporta el error.

            Documentaci√≥n Din√°mica (Swagger Summary):
    """ + (load_swagger_summary() if API_AVAILABLE else "")

    def _clean_content(self, content) -> str:
        """Helper para limpiar respuestas."""
        if isinstance(content, list):
            content = "".join([str(item) for item in content])
        content_str = str(content)
        if content_str.strip().startswith("{") and "'text':" in content_str:
            try:
                data = ast.literal_eval(content_str)
                if isinstance(data, dict) and 'text' in data:
                    return str(data['text'])
            except:
                pass 
        return content_str

    # --- NODO 0: ROUTER (CLASIFICADOR) ---
    async def classify_intent(self, state: AgentState):
        print("üö¶ [Node: Router] Analizando intenci√≥n del usuario...")
        
        prompt = ChatPromptTemplate.from_template(
            """
            Eres el Router Inteligente de Credivibes AI.
            Clasifica la siguiente pregunta en una categor√≠a.

            CATEGOR√çAS:
            1. DATABASE: Para an√°lisis, reportes hist√≥ricos, conteos, estad√≠sticas de usuarios/ventas. (Lo que est√° en SQL).
            2. API: Para consultas de estado en tiempo real, validar un ID espec√≠fico, o informaci√≥n t√©cnica de endpoints.
            3. GENERAL: Saludos o preguntas fuera de contexto.

            Pregunta: "{question}"

            Responde SOLO una palabra: DATABASE, API, o GENERAL.
            """
        )
        chain = prompt | self.llm
        response = await chain.ainvoke({"question": state["question"]})
        intent = self._clean_content(response.content).strip().upper()
        
        # Limpieza extra por si el LLM dice "Es DATABASE"
        if "DATABASE" in intent: intent = "DATABASE"
        elif "API" in intent: intent = "API"
        else: intent = "GENERAL"
            
        print(f"   üëâ Decisi√≥n: {intent}")
        return {"intent": intent}

    # --- NODO 1: SQL GENERATOR (AUTO-CORRECCI√ìN) ---
    async def write_query(self, state: AgentState):
        current_iter = state.get("iterations") or 0
        previous_error = state.get("sql_result", "")
        
        # L√≥gica de Retry / Self-Healing
        is_retry = False
        if previous_error and "Error" in str(previous_error) and current_iter > 0:
            print(f"   ü©π [Self-Healing] Detectado error SQL. Intento de correcci√≥n #{current_iter}...")
            print(f"      contexto: {str(previous_error)[:100]}...")
            is_retry = True

        prompt_template = """
            Eres un arquitecto de bases de datos MySQL experto.
            Tu tarea es generar UNA sola consulta SQL ejecutable para responder a la pregunta del usuario.

            ESTRUCTURA DE TABLAS (Schema):
            {dictionary}

            REGLAS CR√çTICAS:
            1. Usa SOLO sintaxis MySQL est√°ndar.
            2. NO uses Markdown (```sql ... ```). Devuelve solo el c√≥digo.
            3. Si la pregunta busca '√∫ltimos' o rankings, usa LIMIT.
            4. Si hay nombres de columnas ambiguos, usa alias de tabla (t1.columna).
        """

        if is_retry:
            prompt_template += f"""
            
            üö® MODO DE CORRECCI√ìN ACTIVADO üö®
            La consulta anterior FALL√ì con este error:
            "{previous_error}"
            
            ANALIZA EL ERROR Y CORRIGE LA CONSULTA:
            - Si es "no such column": Verifica el diccionario y usa el nombre real.
            - Si es "syntax error": Revisa comas, par√©ntesis y palabras clave.
            - Si es "ambiguous column": A√±ade prefijos de tabla.
            """

        # [FIX] Inyectar contexto de mensajes anteriores para resolver referencias ("y los activos?")
        history_text = ""
        messages = state.get("messages", [])
        if messages:
             # Tomamos los √∫ltimos 4 mensajes omitiendo el actual (que ya est√° en question)
             relevant_msgs = messages[:-1][-4:] 
             if relevant_msgs:
                 history_text = "\nCONTEXTO CONVERSACI√ìN PREVIA:\n" + "\n".join(
                     [f"- {m.type.upper()}: {m.content}" for m in relevant_msgs]
                 )

        prompt_template += f"""
            {history_text}
            
            PREGUNTA ACTUAL: "{{question}}"
            
            SQL Resultante:
        """

        prompt = ChatPromptTemplate.from_template(prompt_template)
        
        chain = prompt | self.llm
        response = await chain.ainvoke({
            "dictionary": self.data_dictionary,
            "question": state["question"]
        })
        
        sql = self._clean_content(response.content).replace("```sql", "").replace("```", "").strip()
        print(f"   üìù Generado SQL: {sql[:60]}...")
        
        return {"sql_query": sql, "iterations": current_iter + 1}

    # --- NODO 2: SQL EXECUTOR ---
    async def execute_query(self, state: AgentState):
        print("‚ö° [Node: Exec] Ejecutando SQL (via MCP)...")
        try:
            # Reemplazo de DatabaseManager por mcp_manager
            # El cliente MCP se conecta al Sidecar que ejecuta la query
            result_json = await mcp_manager.execute_query(state["sql_query"])
            
            # Procesamiento de resultados
            import json
            try:
                rows = json.loads(result_json)
                if isinstance(rows, list) and len(rows) > 15:
                    rows = rows[:15] + [{"note": "...m√°s resultados..."}]
                    return {"sql_result": str(rows)}
            except:
                pass # Si falla el parseo, devolvemos el raw string

            return {"sql_result": result_json}
        except Exception as e:
            print(f"   ‚ùå Error SQL: {e}")
            return {"sql_result": f"Error SQL: {e}"}

    # --- NODO 3: API EXECUTOR (OPTIMIZADO) ---
    async def run_api_tool(self, state: AgentState):
        """
        Ejecuta API utilizando el Agente Singleton (Fast-Path).
        """
        print("üåê [Node: API] Ejecutando llamada a herramienta...")
        
        if not self.api_agent_executor:
            return {"sql_result": "Error: Las herramientas de API no est√°n configuradas."}

        # 2. PREPARAR MEMORIA (CR√çTICO) üß†
        # Obtenemos el historial previo del estado global
        history = state.get("messages", [])
        
        # Truco: Tomamos los √∫ltimos 5 mensajes para dar contexto sin saturar
        recent_history = history[-5:] if history else []

        # 3. Construir la entrada
        # [FIX] Inyectamos SystemMessage manualmente aqu√≠
        input_messages = [SystemMessage(content=self.API_INSTRUCTIONS)] + list(recent_history)
        
        if not recent_history or recent_history[-1].content != state["question"]:
            input_messages.append(HumanMessage(content=state["question"]))

        try:
            # Ejecutamos el grafo pre-compilado
            result = await self.api_agent_executor.ainvoke({"messages": input_messages})
            
            # Recuperamos el √∫ltimo mensaje
            last_message_obj = result["messages"][-1]
            last_message_content = last_message_obj.content
            
            # [OPTIMIZACI√ìN] Eliminado chequeo estricto de herramientas (tool_calls_count == 0)
            # Dado que inyectamos el resumen del Swagger en el SystemPrompt, el agente puede
            # responder preguntas sobre "qu√© endpoints existen" usando su contexto v√°lido sin alucinar.
            # Confiamos en el LLM y el SystemPrompt para no inventar datos.
            
            print(f"   üîô [DEBUG API]: {str(last_message_content)[:300]}...") 
            return {"sql_result": f"[Origen API] {last_message_content}"}
            
        except Exception as e:
            print(f"   ‚ùå Error API: {e}")
            return {"sql_result": f"Error ejecutando API: {str(e)}"}

    # --- NODO 4: RESPUESTA FINAL ---
    async def generate_answer(self, state: AgentState):
        print("üó£Ô∏è [Node: Answer] Resumiendo...")
        
        prompt = ChatPromptTemplate.from_template(
            """
            Responde al usuario bas√°ndote en los datos obtenidos.
            Fuente de datos: {intent}
            Datos: {result}
            Pregunta: {question}
            """
        )
        chain = prompt | self.llm
        res = await chain.ainvoke({
            "intent": state.get("intent", "GENERAL"),
            "result": state.get("sql_result", "Sin datos"),
            "question": state["question"]
        })
        return {"messages": [res]}

--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/core/state.py ---
from typing import TypedDict, Annotated, List, Dict, Any
import operator
from langchain_core.messages import BaseMessage

class AgentState(TypedDict):
    """
    Representa la 'Memoria de Trabajo' del Agente durante una conversaci√≥n.
    LangGraph pasar√° este objeto entre los nodos.
    """
    
    # Historial de chat: Lista de mensajes (Human, AI, Tool)
    # operator.add significa que cuando un nodo devuelve mensajes, se AGREGAN a la lista
    messages: Annotated[List[BaseMessage], operator.add]
    
    # Pregunta original del usuario (para no perder el foco)
    question: str
    
    # El SQL generado por el agente (si ya gener√≥ alguno)
    sql_query: str

    # Resultado de la ejecuci√≥n SQL (o mensaje de error)
    sql_result: str
    
    # Intenci√≥n clasificada (DATABASE / API / GENERAL)
    intent: str
    
    # Contador de iteraciones para reintentos (Self-Healing)
    iterations: int
    
    # El resultado de la consulta SQL (filas de la DB)
    sql_result: str
    
    # (Opcional) Conteo de reintentos por si el SQL falla
    iterations: int
    
    intent: str


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/utils/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/utils/mcp_client.py ---
from typing import Optional, Any

class MCPManager:
    _session: Optional[Any] = None

    def set_session(self, session: Any):
        """Inicializa la sesi√≥n MCP globalmente."""
        self._session = session
        print("‚úÖ [MCP Manager] Sesi√≥n MCP enlazada correctamente.")

    async def call_tool(self, tool_name: str, arguments: dict) -> Any:
        """Invoca una herramienta gen√©rica del Sidecar."""
        if not self._session:
             raise RuntimeError("MCP Session not initialized")
        
        result = await self._session.call_tool(tool_name, arguments=arguments)
        
        # Procesamiento b√°sico de resultados de texto para compatibilidad
        output = ""
        if hasattr(result, 'content') and result.content:
            for item in result.content:
                if hasattr(item, 'text'):
                    output += item.text
                elif isinstance(item, dict) and 'text' in item:
                        output += item['text']
        return output

    async def execute_query(self, query: str) -> str:
        """Ejecuta una query SQL a trav√©s del sidecar MCP."""
        if not self._session:
            raise RuntimeError("‚ö†Ô∏è Intento de usar MCP antes de inicializar la sesi√≥n (Lifespan Error)")
        
        print(f"üì° [MCP Manager] Enviando query: {query[:50]}...")
        
        # Llamada al tool 'query' definido en el Sidecar
        # Nota: La firma puede variar seg√∫n la versi√≥n del SDK, asumimos call_tool est√°ndar
        try:
            result = await self._session.call_tool("query", arguments={"sql": query})
            
            # Extraer texto de la respuesta
            output = ""
            if hasattr(result, 'content') and result.content:
                for item in result.content:
                    if hasattr(item, 'text'):
                        output += item.text
                    elif isinstance(item, dict) and 'text' in item:
                         output += item['text']
            
            return output
            
        except Exception as e:
            print(f"‚ùå [MCP Manager] Error ejecutando tool: {e}")
            raise e

    async def list_tools(self) -> list:
        """Lista las herramientas disponibles en el Sidecar MCP."""
        if not self._session:
            print("‚ö†Ô∏è [MCP Manager] Sesi√≥n no inicializada al listar tools.")
            return []
        
        try:
            result = await self._session.list_tools()
            if hasattr(result, 'tools'):
                return result.tools
            return []
        except Exception as e:
            print(f"‚ùå [MCP Manager] Error listando tools: {e}")
            return []

# Singleton exportado
mcp_manager = MCPManager()


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/utils/logger.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/llm/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/llm/factory.py ---
import os
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI

from agent_core.config.loader import ConfigLoader

class LLMFactory:
    """
    F√°brica actualizada con soporte nativo para DeepSeek V3/R1
    seg√∫n la documentaci√≥n oficial.
    """
    
    @staticmethod
    def create(temperature: float = None) -> BaseChatModel:
        settings = ConfigLoader.load_settings()
        
        provider = settings.get('llm', {}).get('provider', 'google').lower()
        model_name = settings.get('llm', {}).get('model', 'gemini-2.0-flash')
        
        # Si no pasan temperatura, usamos la del settings, o 0 por defecto
        if temperature is None:
            temperature = settings.get('llm', {}).get('temperature', 0)

        print(f"üè≠ LLM Factory: Conectando con {provider.upper()} ({model_name}) | Temp: {temperature}...")

        if provider == "google":
            return ChatGoogleGenerativeAI(
                model=model_name,
                temperature=temperature,
                max_retries=2
            )
        
        elif provider == "deepseek":
            api_key = os.environ.get("DEEPSEEK_API_KEY")
            if not api_key:
                raise ValueError("Falta DEEPSEEK_API_KEY en el archivo .env")
            
            # Configuraci√≥n espec√≠fica seg√∫n Docs de DeepSeek
            return ChatOpenAI(
                model=model_name,
                temperature=temperature,
                api_key=api_key,
                base_url="https://api.deepseek.com", # üëà URL Oficial
                max_retries=2,
                # DeepSeek soporta hasta 64k tokens de salida en algunos casos, 
                # pero por seguridad para SQL dejamos default o ajustamos si cortara.
            )
            
        else:
            raise ValueError(f"Proveedor no soportado: {provider}")

--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/config/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/config/loader.py ---
import os
import yaml
from pathlib import Path
from dotenv import load_dotenv

# Definimos la ra√≠z del proyecto bas√°ndonos en la ubicaci√≥n de este archivo
# src/sql_agent/config/loader.py -> ... -> root
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
CONFIG_DIR = BASE_DIR / "config"
load_dotenv(BASE_DIR / ".env")

class ConfigLoader:
    """
    Singleton encargado de cargar la configuraci√≥n una sola vez.
    """
    _settings = None
    _business_context = None

    @classmethod
    def load_settings(cls):
        """Carga config/settings.yaml"""
        if cls._settings is None:
            path = CONFIG_DIR / "settings.yaml"
            try:
                with open(path, "r", encoding="utf-8") as f:
                    cls._settings = yaml.safe_load(f)
            except FileNotFoundError:
                # Fallback por si no existe
                cls._settings = {"app": {"debug": True}}
                print(f"‚ö†Ô∏è Alerta: No se encontr√≥ {path}, usando valores por defecto.")
        return cls._settings

    
    @staticmethod
    def _find_project_root():
        # src/agent_core/config/loader.py -> ... -> root
        current_dir = os.path.dirname(os.path.abspath(__file__))
        
        # Subir 4 niveles para llegar a la ra√≠z del monorepo (desde src/agent_core/config)
        # apps/agent-host/src/agent_core/config -> apps/agent-host/src/agent_core -> apps/agent-host/src -> apps/agent-host -> root
        # Ajustar seg√∫n estructura real
        return os.path.abspath(os.path.join(current_dir, "../../../../"))

--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/api/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/agent_core/api/loader.py ---
import os
import json
from typing import List, Dict

from langchain_community.agent_toolkits.openapi.toolkit import RequestsToolkit
from langchain_community.utilities.requests import RequestsWrapper
from langchain_community.tools.json.tool import JsonSpec
from agent_core.llm.factory import LLMFactory
from dotenv import load_dotenv

load_dotenv()

def _get_swagger_path():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.abspath(os.path.join(current_dir, "../../../"))
    return os.path.join(project_root, "docs", "swagger.json")

def load_swagger_summary() -> str:
    """Genera un resumen ligero de la API para el prompt del sistema."""
    try:
        path = _get_swagger_path()
        if not os.path.exists(path): return "No API spec found."
        
        with open(path, 'r', encoding='utf-8') as f:
            spec = json.load(f)
            
        summary = ["API ENDPOINTS DISPONIBLES:"]
        for path, methods in spec.get("paths", {}).items():
            for method, details in methods.items():
                desc = details.get("summary") or details.get("description") or "Sin descripci√≥n"
                summary.append(f"- {method.upper()} {path} : {desc[:100]}") # Truncar descripci√≥n
        
        return "\n".join(summary)
    except Exception as e:
        return f"Error leyendo spec: {e}"

def load_api_tools() -> List:
    """
    Cargador Ligero (RequestsToolkit).
    Ya no usa OpenAPIToolkit pesado. Retorna solo herramientas HTTP gen√©ricas.
    El contexto se pasa v√≠a SystemPrompt (load_swagger_summary).
    """
    print("üîå [API Loader] Inicializando herramientas HTTP (Light Mode)...")
    
    # ... (Auth logic remains same) ...
    swagger_path = _get_swagger_path()
    
    # 2. Configurar Autenticaci√≥n Din√°mica
    auth_header = os.getenv("API_AUTH_HEADER")
    auth_value = os.getenv("API_AUTH_VALUE")
    
    headers = {
        "Content-Type": "application/json"
    }
    
    if auth_header and auth_value:
        print(f"   üîë Inyectando credenciales din√°micas en header: '{auth_header}'")
        headers[auth_header] = auth_value
    else:
        print("   ‚ö†Ô∏è ADVERTENCIA: No se definieron API_AUTH_HEADER o API_AUTH_VALUE en .env")

    try:
        # Inyecci√≥n din√°mica de servidor para RequestsWrapper
        with open(swagger_path, 'r', encoding='utf-8') as f:
             raw_spec = json.load(f)
             
        env_base_url = os.getenv("API_BASE_URL")
        # Si no hay env, intentamos sacar del swagger
        if not env_base_url and "servers" in raw_spec:
             env_base_url = raw_spec["servers"][0].get("url")
             
        if not env_base_url:
            print("   ‚ö†Ô∏è No se encontr√≥ Base URL. Las llamadas pueden fallar.")
        else:
            # FIX: LangChain RequestsToolkit NO usa el base_url del wrapper autom√°ticamente.
            # Debemos actualizar las especificaciones del swagger al vuelo o usar rutas absolutas.
            # Alternativa simple: Inyectar la URL correcta en las herramientas de langchain es complejo.
            # Mejor opci√≥n: Actualizar la spec cargada en memoria si se usara OpenAPIToolkit,
            # pero como usamos RequestsToolkit crudo, este NO tiene concepto de "base_url" por defecto.
            # RequestsWrapper SI acepta params, pero no base_url directo en __init__.
            pass

        # Creamos la wrapper con Headers
        
        # [CRITICAL FIX] Subclaseamos para interceptar llamadas y arreglar URLs relativas
        # Esto evita el error de Pydantic al intentar monkeypatching en una instancia.
        class BaseUrlRequestsWrapper(RequestsWrapper):
            def _clean_url(self, url: str) -> str:
                clean_url = str(url).strip().strip("'").strip('"')
                target_url = clean_url
                if env_base_url and not clean_url.lower().startswith("http"):
                    base = env_base_url.rstrip("/")
                    path = clean_url.lstrip("/")
                    target_url = f"{base}/{path}"
                    print(f"   üîÑ [URL Rewrite] '{clean_url}' -> '{target_url}'")
                return target_url

            def get(self, url: str, **kwargs):
                target_url = self._clean_url(url)
                return super().get(target_url, **kwargs)

            async def aget(self, url: str, **kwargs):
                target_url = self._clean_url(url)
                return await super().aget(target_url, **kwargs)

        requests_wrapper = BaseUrlRequestsWrapper(headers=headers)
        
        toolkit = RequestsToolkit(requests_wrapper=requests_wrapper, allow_dangerous_requests=True)
        all_tools = toolkit.get_tools()
        
        # [OPTIMIZACI√ìN] Filtramos para dejar SOLO GET (Lectura Segura)
        final_tools = []
        for tool in all_tools:
            if tool.name == "requests_get":
                # Avisamos en la descripci√≥n que la Base URL es autom√°tica
                if env_base_url:
                    tool.description += f" (Note: Base URL '{env_base_url}' is AUTOMATICALLY prepended to relative paths. Do NOT guess domains.)"
                final_tools.append(tool)
        
        print(f"   ‚úÖ Herramientas ligeras cargadas: {len(final_tools)} (Solo GET - Read Only).")
        return final_tools

    except Exception as e:
        print(f"   ‚ùå Error cargando herramientas API: {e}")
        return []


if __name__ == "__main__":
    load_api_tools()

--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/infra/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/infra/mcp/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/infra/mcp/loader.py ---
from typing import List, Any, Dict, Type, Optional
from langchain_core.tools import StructuredTool, BaseTool
from mcp import ClientSession
from pydantic import BaseModel, create_model, Field

def _create_args_schema(tool_name: str, schema: Dict[str, Any]) -> Type[BaseModel]:
    """
    Creates a Pydantic model from a JSON Schema.
    Simplistic implementation for flat schemas common in our MCP tools.
    """
    fields = {}
    properties = schema.get("properties", {})
    required = set(schema.get("required", []))
    
    # Mapping simplified for common JSON types
    type_map = {
        "string": str,
        "integer": int,
        "number": float,
        "boolean": bool,
        "array": list,
        "object": dict
    }

    for prop_name, prop_def in properties.items():
        json_type = prop_def.get("type", "string")
        # Handle simple type mapping
        py_type = type_map.get(json_type, Any)
        
        description = prop_def.get("description", "")
        
        # Determine if required or optional
        if prop_name in required:
            fields[prop_name] = (py_type, Field(..., description=description))
        else:
            fields[prop_name] = (Optional[py_type], Field(None, description=description))
            
    # Create the model dynamically
    # Use a sanitized name for the class
    safe_name = tool_name.replace("-", "_").replace(" ", "_").capitalize() + "Schema"
    return create_model(safe_name, **fields)

async def get_agent_tools(session: Any) -> List[BaseTool]:
    """
    Manual implementation of MCP to LangChain tool conversion 
    to avoid library version mismatches and 'config' arg errors.
    """
    if not session:
        print("‚ö†Ô∏è Warning: session is None in get_agent_tools")
        return []

    try:
        # 1. Fetch tool definitions
        print("üîç Fetching tools from MCP session...")
        result = await session.list_tools()
        tools: List[BaseTool] = []

        print(f"üì¶ Found {len(result.tools)} tools from sidecar.")

        for tool_def in result.tools:
            # 2. Create Dynamic Pydantic Model for Arguments
            input_schema = tool_def.inputSchema or {}
            # print(f"  - Processing tool: {tool_def.name}")
            args_model = _create_args_schema(tool_def.name, input_schema)
            
            # 3. Define the async execution function
            # We capture 'name' via default arg to avoid loop variable binding issues
            # We use **kwargs to match the Pydantic model fields flatly
            async def _run_tool(
                _tool_name: str = tool_def.name,
                **kwargs
            ) -> str:
                try:
                    # print(f"‚ñ∂Ô∏è Executing tool: {_tool_name} with args: {kwargs}")
                    
                    # Validate: filter out any None values for optional args if needed, 
                    # but MCP usually handles nulls fine.
                    
                    # Filter arguments that are not in the schema (Langchain might inject others)
                    # Actually, **kwargs captures what matched the schema.
                    
                    call_result = await session.call_tool(_tool_name, arguments=kwargs)
                    
                    # Process result content
                    output_text = []
                    if call_result.content:
                        for content in call_result.content:
                            if content.type == 'text':
                                output_text.append(content.text)
                            elif content.type == 'image':
                                output_text.append("[Image Content Not Supported]")
                            elif content.type == 'resource':
                                output_text.append(f"[Resource: {content.resource.uri}]")
                                
                    final_text = "\n".join(output_text)
                    if call_result.isError:
                        return f"Error from tool {_tool_name}: {final_text}"
                    return final_text
                except Exception as e:
                    import traceback
                    print(f"‚ùå Exception in tool {_tool_name}: {type(e).__name__}: {e}")
                    traceback.print_exc()
                    error_msg = str(e)
                    if not error_msg:
                        error_msg = f"{type(e).__name__} (No details provided)"
                    return f"Error executing tool {_tool_name}: {error_msg}"

            # 4. Wrap with LangChain's StructuredTool
            langchain_tool = StructuredTool.from_function(
                coroutine=_run_tool,
                name=tool_def.name,
                description=tool_def.description or "",
                args_schema=args_model,
                # Avoid validation errors from extra args
                # infer_schema=False is implied by providing args_schema
            )
            
            tools.append(langchain_tool)
            
        return tools

    except Exception as e:
        print(f"‚ùå Error loading MCP tools manually: {e}")
        import traceback
        traceback.print_exc()
        return []



--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/infra/mcp/manager.py ---
import asyncio
from contextlib import AsyncExitStack
from typing import Optional, Any
from mcp import ClientSession
from mcp.client.sse import sse_client
import anyio

class MCPSessionManager:
    """
    Wrapper around MCP ClientSession that handles auto-reconnection
    on network failures or timeouts.
    """
    def __init__(self, sidecar_url: str):
        self.sidecar_url = sidecar_url
        self.session: Optional[ClientSession] = None
        self._exit_stack: Optional[AsyncExitStack] = None
        self._lock = asyncio.Lock()

    async def connect(self):
        """Initial connection."""
        async with self._lock:
            if self.session:
                return
            await self._connect_unsafe()

    async def _connect_unsafe(self):
        print(f"üîÑ MCP Manager: Connecting to {self.sidecar_url}...")
        self._exit_stack = AsyncExitStack()
        try:
            sse = sse_client(url=f"{self.sidecar_url}/sse", timeout=None)
            streams = await self._exit_stack.enter_async_context(sse)
            
            self.session = await self._exit_stack.enter_async_context(
                ClientSession(streams[0], streams[1])
            )
            await self.session.initialize()
            print("‚úÖ MCP Manager: Connected and Initialized.")
        except Exception as e:
            print(f"‚ùå MCP Manager Connection Failed: {e}")
            await self.close()
            raise e

    async def close(self):
        """Explicit cleanup."""
        # Lock to ensure we don't close while connecting in another task
        # But for simplicity, we just clean up.
        if self._exit_stack:
            try:
                await self._exit_stack.aclose()
            except Exception as e:
                print(f"‚ö†Ô∏è Error closing stack: {e}")
        self.session = None
        self._exit_stack = None

    async def ensure_active(self):
        """Check connection or reconnect if needed."""
        if not self.session:
            await self.connect()

    async def list_tools(self):
        await self.ensure_active()
        try:
            # We assume session exists after ensure_active
            return await self.session.list_tools()
        except Exception as e:
            print(f"‚ö†Ô∏è List tools failed ({e}), attempting reconnect...")
            await self.close()
            await self.connect()
            return await self.session.list_tools()

    async def call_tool(self, name: str, arguments: dict) -> Any:
        """
        Calls a tool with auto-reconnect logic.
        """
        # Retry loop (max 1 retry for connection issues)
        for attempt in range(2):
            await self.ensure_active()
            try:
                return await self.session.call_tool(name, arguments=arguments)
            except Exception as e:
                # Detect specific connection errors
                is_closed = isinstance(e, (anyio.ClosedResourceError, anyio.EndOfStream, ConnectionError))
                msg = str(e).lower()
                if "closed" in msg or "connection" in msg:
                    is_closed = True

                if is_closed and attempt == 0:
                    print(f"‚ö†Ô∏è Connection lost during tool call '{name}'. Reconnecting...")
                    await self.close()
                    # Small backoff
                    await asyncio.sleep(0.5)
                    continue
                else:
                    # Propagate other errors (logic errors, tool errors) or if retry failed
                    raise e


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/features/sql_analysis/loader.py ---
import os
import yaml
from pathlib import Path
from langchain_core.messages import SystemMessage
from infra.mcp.loader import get_agent_tools as get_mcp_tools # Reusing existing generic MCP loader if possible
# Assuming infra/mcp/loader.py is generic enough. Let's verify that first.

# We need to calculate paths relative to this feature
# apps/agent-host/src/features/sql_analysis/loader.py

# Detecci√≥n inteligente del entorno (Docker vs Local)
# En Docker, WORKDIR es /app, as√≠ que config suele estar en /app/config
DOCKER_CONFIG_PATH = Path("/app/config")

if DOCKER_CONFIG_PATH.exists():
    CONFIG_DIR = DOCKER_CONFIG_PATH
else:
    # Fallback para entorno local (Monorepo)
    # Subimos niveles hasta encontrar la carpeta config en la ra√≠z del proyecto
    # src/features/sql_analysis/loader.py -> ... -> sql-agent-oss/config
    BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent.parent
    CONFIG_DIR = BASE_DIR / "config"

SYSTEM_PROMPT_TEMPLATE = """Eres un experto Agente SQL.

‚ö†Ô∏è REGLAS CR√çTICAS DE SEGURIDAD ‚ö†Ô∏è
1. PROHIBIDO ejecutar `SELECT *` en la tabla `users`. Contiene columnas de im√°genes Base64 (doc_photo, selfie_photo) que rompen la conexi√≥n.
2. ANTES de consultar `users`, SIEMPRE ejecuta `DESCRIBE users` para ver las columnas disponibles.
3. Selecciona SIEMPRE columnas espec√≠ficas (ej. `SELECT id, name, email FROM users...`).
4. Para otras tablas, inspecciona primero el esquema igualmente.

üé® ESTILO DE RESPUESTA:
- S√© amable y conciso.
- EVITA el uso excesivo de saltos de l√≠nea (\\n).
- Cuando listes datos simples (como nombres), √∫salos separados por comas.
"""

def load_business_context() -> str:
    """Loads business context from YAML"""
    path = CONFIG_DIR / "business_context.yaml"
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        print(f"‚ö†Ô∏è Alerta: No se encontr√≥ {path}")
        return "Sin contexto definido."

def get_sql_system_prompt() -> str:
    """Generates the full system prompt for SQL Analysis"""
    context = load_business_context()
    return f"""{SYSTEM_PROMPT_TEMPLATE}

üìò CONTEXTO DE NEGOCIO Y DICCIONARIO DE DATOS:
A continuaci√≥n se definen las entidades, sin√≥nimos y reglas de negocio. √öSALO para entender qu√© tabla consultar seg√∫n los t√©rminos del usuario.

```yaml
{context}
```
"""

async def get_sql_tools(mcp_manager):
    """Facade to get tools for this specific feature"""
    # In the future, this could filter specific tools from the MCP session if needed
    from agent_core.api.loader import load_api_tools
    
    mcp_tools = await get_mcp_tools(mcp_manager)
    api_tools = load_api_tools() # Reads config from env
    
    return mcp_tools + api_tools


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/channels/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/channels/whatsapp/__init__.py ---


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/channels/whatsapp/router.py ---
import os
import httpx
from fastapi import APIRouter, Request, HTTPException, BackgroundTasks
from langchain_core.messages import HumanMessage
from infra.mcp.manager import MCPSessionManager

# Imports de la arquitectura Hybrid Slice
from agent_core.graph import build_graph
from features.sql_analysis.loader import get_sql_tools, get_sql_system_prompt

# Configuraci√≥n del canal
router = APIRouter(tags=["WhatsApp Channel"])
WAHA_BASE_URL = os.getenv("WAHA_BASE_URL", "http://waha:3000")
WAHA_API_KEY = os.getenv("WAHA_API_KEY")
SIDECAR_URL = os.getenv("SIDECAR_URL", "http://mcp-mysql:3000")

async def process_message(chat_id: str, message_text: str):
    """
    Proceso background: 
    1. Conecta infraestructura (MCP)
    2. Carga funcionalidades (SQL Feature)
    3. Ejecuta pensamiento (Agent Core)
    4. Env√≠a respuesta (WhatsApp API)
    """
    mcp_manager = MCPSessionManager(SIDECAR_URL)
    
    try:
        print(f"üì© [WhatsApp Channel] Procesando mensaje de {chat_id}")
        
        # 1. Infraestructura
        await mcp_manager.connect()
        
        # 2. Cargar Feature (SQL Analysis)
        tools = await get_sql_tools(mcp_manager)
        system_prompt = get_sql_system_prompt()
        
        # 3. Construir Cerebro con la feature inyectada
        # TODO: A√±adir persistencia real (checkpointer) para mantener hilos por chat_id
        agent = build_graph(tools=tools, system_prompt=system_prompt)
        
        config = {"configurable": {"thread_id": chat_id}}
        inputs = {"messages": [HumanMessage(content=message_text)]}
        
        # 4. Ejecutar
        result = await agent.ainvoke(inputs, config=config)
        bot_response = result["messages"][-1].content
        
        # 5. Responder
        headers = {}
        if WAHA_API_KEY:
            headers["X-Api-Key"] = WAHA_API_KEY

        async with httpx.AsyncClient() as client:
            await client.post(
                f"{WAHA_BASE_URL}/api/sendText",
                json={
                    "chatId": chat_id, 
                    "text": bot_response, 
                    "session": "default"
                },
                headers=headers,
                timeout=10.0
            )
            print(f"‚úÖ [WhatsApp Channel] Respuesta enviada a {chat_id}")

    except Exception as e:
        print(f"‚ùå [WhatsApp Channel] Error cr√≠tico: {e}")
        # Intentar enviar mensaje de error al usuario si es posible
    finally:
        await mcp_manager.close()

@router.post("/webhook")
async def whatsapp_webhook(request: Request, background_tasks: BackgroundTasks):
    """
    Entrypoint ligero. Recibe el evento, valida y delega a background tasks.
    """
    try:
        data = await request.json()
        
        # 1. Validaci√≥n de estructura WAHA
        if data.get("event") != "message":
            return {"status": "ignored", "reason": "not_a_message_event"}
            
        payload = data.get("payload", {})
        
        # 2. Evitar bucles infinitos (mensajes propios)
        if payload.get("fromMe"):
            return {"status": "ignored", "reason": "from_me"}
            
        chat_id = payload.get("chatId")
        body = payload.get("body")

        # 3. Encolar tarea
        if chat_id and body:
            background_tasks.add_task(process_message, chat_id, body)
            return {"status": "processing"}
        
        return {"status": "ignored", "reason": "no_content"}

    except Exception as e:
        print(f"‚ùå [WhatsApp Webhook] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


--- FILE: /home/davidrbh/Documents/projects/sql-agent-oss/apps/agent-host/src/api/server.py ---
import os
from fastapi import FastAPI
from contextlib import asynccontextmanager
from chainlit.utils import mount_chainlit

# --- CANALES (Channels) ---
from channels.whatsapp.router import router as whatsapp_router
from dotenv import load_dotenv

load_dotenv()

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup logic if any
    print("üöÄ Server starting...")
    yield
    print("üõë Server shutting down...")

app = FastAPI(lifespan=lifespan)

# --- 1. Canal WhatsApp (Webhook) ---
app.include_router(whatsapp_router, prefix="/whatsapp")

# --- 2. Health Check ---
@app.get("/health")
async def health_check():
    return {"status": "ok", "architecture": "hybrid-slice"}

# --- 3. Canal UI (Chainlit) ---
# Montamos la UI en la ra√≠z.
# Chainlit tomar√° el control de "/" y socket.io
# IMPORTANTE: target es relativo al directorio de ejecuci√≥n (root del repo en docker)
# En docker: WORKDIR /app
# src est√° en /app/src
# main.py est√° en /app/src/main.py
mount_chainlit(app=app, target="src/main.py", path="/")

